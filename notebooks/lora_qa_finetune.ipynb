{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrosaria/Projects/NLP/GymRat/ratenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb9bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_private_keys(key_name):\n",
    "    load_dotenv()\n",
    "    key = os.getenv(key_name)\n",
    "    if not key:\n",
    "        raise ValueError(f\"Missing key for {key_name} in .env\") \n",
    "    return key\n",
    "\n",
    "huggingface_hub_token = get_private_keys(\"huggingface_hub\")\n",
    "login(token=huggingface_hub_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d8e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6fccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_file_name = \"cleaned_1506_raw_outputs_samples1260_nreps3_new_tok256_chuck_size250_overlap30_.json\"\n",
    "#\n",
    "# input_json_file_name = \"cleaned_1506_raw_outputs_samples1260_nreps3_new_tok256_chuck_size250_overlap30_.json\"\n",
    "# with open(input_json_file_name, \"r\") as f:\n",
    "#     loaded_list = json.load(f)\n",
    "\n",
    "#input_json_file_name = \"cleaned_343_qa_outputs_800_batch16_4bit_30072025.json\"\n",
    "# Load the dataset from JSON file\n",
    "dataset = load_dataset(\"json\", data_files=input_json_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e39287",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "dataset = splits[\"train\"]\n",
    "test_dataset = splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f472e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'instruction' and 'output' as prompt and target\n",
    "def format_example(example):\n",
    "    prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3405eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"Squeezing your arms tight to your rib cage while engaging your powerful lat muscles and creating a tremendous amount of core stiffness and upper body stability. Next, engage the rest of your upper body by pulling upward against the bar, not moving it from the raised platform yet, but enough to essentially wedge your body against the bar like a trust fall. If you're doing it correctly, you'll see the bar bend upward slightly. To create this tension with your upper body, you need to simultaneously do the opposite with your lower body. This means creating a tremendous amount of tension in your glutes and hamstrings as you drive your feet hard into the ground. Finding the right balance?.\", 'output': 'Micah Mariano deadlift while creating a tremendous amount of tension in your glutes and hamstrings while driving your feet hard into the ground.', 'text': \"### Instruction:\\nSqueezing your arms tight to your rib cage while engaging your powerful lat muscles and creating a tremendous amount of core stiffness and upper body stability. Next, engage the rest of your upper body by pulling upward against the bar, not moving it from the raised platform yet, but enough to essentially wedge your body against the bar like a trust fall. If you're doing it correctly, you'll see the bar bend upward slightly. To create this tension with your upper body, you need to simultaneously do the opposite with your lower body. This means creating a tremendous amount of tension in your glutes and hamstrings as you drive your feet hard into the ground. Finding the right balance?.\\n\\n### Response:\\nMicah Mariano deadlift while creating a tremendous amount of tension in your glutes and hamstrings while driving your feet hard into the ground.\"}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(format_example)\n",
    "test_dataset = test_dataset.map(format_example)\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c18203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",  # You can also use \"fp4\"\n",
    "#     bnb_4bit_compute_dtype=\"float16\"\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=quant_config,\n",
    "#     trust_remote_code=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f6d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     load_in_4bit=True,  # Optional: enable quantization to save memory\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# # Apply LoRA\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # Tokenize the dataset\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Training setup\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./lora-llama-output\",\n",
    "#     per_device_train_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     learning_rate=2e-4,\n",
    "#     num_train_epochs=3,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     fp16=True,\n",
    "#     save_total_limit=2,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=500,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator\n",
    "# )\n",
    "\n",
    "# # Start training\n",
    "# trainer.train()\n",
    "#TrainOutput(global_step=129, training_loss=1.575617376224015, metrics={'train_runtime': 199.0944, 'train_samples_per_second': 5.168, 'train_steps_per_second': 0.648, 'total_flos': 3273745332436992.0, 'train_loss': 1.575617376224015, 'epoch': 3.0})\n",
    "## new_model_name = \"tinyllama-qa-343samples-finetuned-30072025\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0247b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:00<00:00, 4155.94 examples/s]\n",
      "/tmp/ipykernel_979850/1998495725.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='850' max='850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [850/850 35:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.476200</td>\n",
       "      <td>1.503343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.467700</td>\n",
       "      <td>1.439405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.407400</td>\n",
       "      <td>1.426077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.362700</td>\n",
       "      <td>1.420144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.359200</td>\n",
       "      <td>1.415425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.478300</td>\n",
       "      <td>1.412378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1.412556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.381600</td>\n",
       "      <td>1.411611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=850, training_loss=1.421143362381879, metrics={'train_runtime': 2160.1019, 'train_samples_per_second': 6.273, 'train_steps_per_second': 0.393, 'total_flos': 4.31090857672704e+16, 'train_loss': 1.421143362381879, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Updated after 1st atempt\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  #or \"fp4\"\n",
    "    bnb_4bit_compute_dtype=\"float16\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    #r=8, With small data, a smaller r (e.g., 4) might prevent overfitting\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "    lora_dropout=0.05, #You could try slightly higher (0.1) if overfitting.\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_val = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama-output\",\n",
    "    #per_device_train_batch_size=2 with gradient_accumulation_steps=4 is fine (effective batch size 8).\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #learning_rate=2e-4, 2e-4 is a bit high for fine-tuning on a small dataset. It can cause unstable training or forgetting.\n",
    "    learning_rate=1e-4,#1e-5,\n",
    "    #num_train_epochs=3, #With only ~300 samples, 3 epochs might be too little.\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\", \n",
    "    #Add weight decay, Helps regularize, reduce overfitting.\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    # Used train data also as eval\n",
    "    eval_dataset=tokenized_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "#old  TrainOutput(global_step=129, training_loss=1.575617376224015, metrics={'train_runtime': 199.0944, 'train_samples_per_second': 5.168, 'train_steps_per_second': 0.648, 'total_flos': 3273745332436992.0, 'train_loss': 1.575617376224015, 'epoch': 3.0})\n",
    "#this TrainOutput(global_step=860, training_loss=1.7047795207001442, metrics={'train_runtime': 1317.3933, 'train_samples_per_second': 5.207, 'train_steps_per_second': 0.653, 'total_flos': 2.181310005116928e+16, 'train_loss': 1.7047795207001442, 'epoch': 20.0})\n",
    "#Step\tTraining Loss\tValidation Loss\n",
    "# 100\t1.906100\t1.956670\n",
    "# 200\t1.908100\t1.838620\n",
    "# 300\t1.737400\t1.735574\n",
    "# 400\t1.606700\t1.687118\n",
    "# 500\t1.622300\t1.645923\n",
    "# 600\t1.599600\t1.621207\n",
    "# 700\t1.585900\t1.607686\n",
    "# 800\t1.379700\t1.601775\n",
    "#new_model_name = \"tinyllama-v2-qa-343samples-finetuned-31072025\"\n",
    "\n",
    "\n",
    "#Current with 1230 samples\n",
    "#TrainOutput(global_step=1425, training_loss=1.6043405378910534, metrics={'train_runtime': 4848.0399, 'train_samples_per_second': 4.66, 'train_steps_per_second': 0.294, 'total_flos': 7.183060206354432e+16, 'train_loss': 1.6043405378910534, 'epoch': 15.0})\n",
    "\n",
    "#with 1230 samples, minus eval 10%, 10 epochs, r=8,  learning_rate=1e-4 08/08/2025\n",
    "#TrainOutput(global_step=850, training_loss=1.421143362381879, metrics={'train_runtime': 2160.1019, 'train_samples_per_second': 6.273, 'train_steps_per_second': 0.393, 'total_flos': 4.31090857672704e+16, 'train_loss': 1.421143362381879, 'epoch': 10.0})\n",
    "# Step\tTraining Loss\tValidation Loss\n",
    "# 100\t1.476200\t1.503343\n",
    "# 200\t1.467700\t1.439405\n",
    "# 300\t1.407400\t1.426077\n",
    "# 400\t1.362700\t1.420144\n",
    "# 500\t1.359200\t1.415425\n",
    "# 600\t1.478300\t1.412378\n",
    "# 700\t1.325800\t1.412556\n",
    "# 800\t1.381600\t1.411611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9646651a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainOutput' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mTrainOutput\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'TrainOutput' is not defined"
     ]
    }
   ],
   "source": [
    "TrainOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44cff1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tinyllama-v2-qa-343samples-finetuned-08082025/tokenizer_config.json',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-08082025/special_tokens_map.json',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-08082025/chat_template.jinja',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-08082025/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model_name = \"tinyllama-qa-343samples-finetuned-30072025\"\n",
    "new_model_name = \"tinyllama-v2-qa-343samples-finetuned-08082025\"\n",
    "\n",
    "trainer.save_model(new_model_name)\n",
    "tokenizer.save_pretrained(new_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0fca1",
   "metadata": {},
   "source": [
    "# Test NEW model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03445061",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3043de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d2843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Base (Unmodified) Model\n",
    "base_model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45766040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tinyllama-v2-qa-343samples-finetuned-04082025'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load MY Fine-Tuned LoRA Model\n",
    "peft_model_dir = f\"{new_model_name}\"  # Your trained adapter folder\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "\n",
    "# Load base model and apply LoRA weights\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "finetuned_model = PeftModel.from_pretrained(finetuned_model, peft_model_dir)\n",
    "\n",
    "finetuned_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a4b0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Base Model Output:\n",
      " <|user|>\n",
      "What is the importance of proper recovery in powerlifting?</s>\n",
      "<|assistant|>\n",
      "Proper recovery is crucial for powerlifters because it allows them to rebuild and repair their muscles, improve their strength, and prepare for the next set of lifts. Proper recovery can help to reduce muscle soreness, improve blood flow to the muscles, and promote muscle growth and repair. Proper recovery also helps to prevent injury by ensuring that the body is fully recovered from the previous set of lifts. Recovery is particularly important for powerlifters who perform repeated sets of heavy lifts over long periods. Without proper recovery, the body may become fatigued and prone to injury. Overall, proper recovery is an essential part of powerlifting and plays a significant role in achieving maximum strength and performance.\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Output:\n",
      " <|user|>\n",
      "What is the importance of proper recovery in powerlifting?</s>\n",
      "<|assistant|>\n",
      "Proper recovery is crucial in powerlifting. It helps in the recovery and regeneration of muscles, reducing the risk of injuries and improving performance. Recovery involves a series of activities designed to restore muscle tissue and reduce muscle soreness.\n",
      "\n",
      "Powerlifting is a high-intensity sport, and proper recovery is essential to prevent injuries and maintain optimal performance. It involves a series of exercises, called sets and reps, that target specific muscle groups. The process of recovery involves rest, stretching, and nutrition.\n",
      "\n",
      "Proper recovery is not just about resting after a workout. It also involves stretching and nutrition. Stretching helps to release lactic acid from the muscles, which reduces muscle soreness and improves performance. Nutrition, on the other hand, helps in the recovery of muscles by providing the body with the necessary nutrients to repair and regenerate muscle tissue.\n",
      "\n",
      "Proper recovery is essential for maintaining optimal performance and preventing injuries in powerlifting. It helps in the recovery and regeneration of muscles, reducing the risk of injuries and improving performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"What is the importance of proper recovery in powerlifting?\"\n",
    "prompt = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "formatted_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Base model generation\n",
    "base_pipe = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer)\n",
    "base_output = base_pipe(formatted_prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)[0][\"generated_text\"]\n",
    "\n",
    "# Fine-tuned model generation\n",
    "finetuned_pipe = pipeline(\"text-generation\", model=finetuned_model, tokenizer=tokenizer)\n",
    "finetuned_output = finetuned_pipe(formatted_prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)[0][\"generated_text\"]\n",
    "\n",
    "# Compare\n",
    "print(\"ðŸ”¹ Base Model Output:\\n\", base_output)\n",
    "print(\"\\nðŸ”¸ Fine-Tuned Model Output:\\n\", finetuned_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb1aea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "how to screen for understanding shoulder pain? \n",
      "<|assistant|>\n",
      "To screen for understanding shoulder pain, the following steps can be followed:\n",
      "\n",
      "1. Perform a thorough examination of the shoulder joint, including a thorough evaluation of shoulder range of motion, shoulder movement patterns, and shoulder pain.\n",
      "\n",
      "2. Ask the patient to perform a shoulder range of motion exercise, such as bending the arm and rotating the arm, to assess the patient's shoulder mobility.\n",
      "\n",
      "3. Evaluate the patient's shoulder pain by asking about any specific symptoms or areas of pain, such as a lump or a clicking sound in the shoulder joint.\n",
      "\n",
      "4. Assess the patient's ability to perform daily activities, such as brushing their teeth, using a cup, or turning a chair, to determine if the shoulder pain is impacting their daily functioning.\n",
      "\n",
      "5. Ask the patient about any changes in their shoulder function or range of motion over the past few weeks, and consider any changes in their shoulder activities, such as changing jobs or engaging in physical activities that may cause shoulder pain.\n",
      "\n",
      "6. Review the patient's medical history, including any previous shoulder surgeries, injuries, or medications, to determine if any of these factors may be contributing\n"
     ]
    }
   ],
   "source": [
    "message = \"how to screen for understanding shoulder pain?\"\n",
    "#\"What is the 'no pain, no gain' mantra?\"\n",
    "#\"What is the importance of proper recovery in powerlifting?\"\n",
    "prompt = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "formatted_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "\n",
    "outputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")  # or \"cpu\"\n",
    "response_base_model = base_model.generate(\n",
    "    **outputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,         # enables sampling for variability\n",
    "    top_p=0.9,               # nucleus sampling\n",
    "    temperature=0.7,         # randomness control\n",
    "    pad_token_id=tokenizer.eos_token_id  # avoid pad token issues\n",
    ")\n",
    "decoded_base_model = tokenizer.decode(response_base_model[0], skip_special_tokens=True)\n",
    "print(decoded_base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d1558d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "how to screen for understanding shoulder pain? \n",
      "<|assistant|>\n",
      "To screen for understanding shoulder pain, you can use the following techniques:\n",
      "\n",
      "1. Neck Mobility Test: Stand with your back against a wall and hold your head in a neutral position. Slowly raise your head and neck until you feel a tightness or pain in your neck. If you feel pain, this is an indication that your shoulder may be experiencing shoulder pain.\n",
      "\n",
      "2. Shoulder Raising Test: Stand with your back against a wall and hold your arms out to the sides. Slowly raise your arms until you feel a tightness or pain in your shoulder. If you feel pain, this is an indication that your shoulder may be experiencing shoulder pain.\n",
      "\n",
      "3. Pain Test: Place your hand on your shoulder and feel for any pain or discomfort. If you feel any pain or discomfort, this is an indication that your shoulder may be experiencing shoulder pain.\n",
      "\n",
      "4. Range of Motion Test: Stand with your back against a wall and hold your arms out to the sides. Slowly move your arms out to the sides until you feel a tightness or pain in your shoulder. If you feel pain, this is an indication that your shoulder\n"
     ]
    }
   ],
   "source": [
    "outputs_finetunned = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")  # or \"cpu\"\n",
    "\n",
    "response_finetunned_model = finetuned_model.generate(\n",
    "    **outputs_finetunned,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,         # enables sampling for variability\n",
    "    top_p=0.9,               # nucleus sampling\n",
    "    temperature=0.7,         # randomness control\n",
    "    pad_token_id=tokenizer.eos_token_id  # avoid pad token issues\n",
    ")\n",
    "decoded_finetunned_model = tokenizer.decode(response_finetunned_model[0], skip_special_tokens=True)\n",
    "print(decoded_finetunned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "To screen for understanding shoulder pain, you can use the following techniques:\n",
       "\n",
       "1. Neck Mobility Test: Stand with your back against a wall and hold your head in a neutral position. Slowly raise your head and neck until you feel a tightness or pain in your neck. If you feel pain, this is an indication that your shoulder may be experiencing shoulder pain.\n",
       "\n",
       "2. Shoulder Raising Test: Stand with your back against a wall and hold your arms out to the sides. Slowly raise your arms until you feel a tightness or pain in your shoulder. If you feel pain, this is an indication that your shoulder may be experiencing shoulder pain.\n",
       "\n",
       "3. Pain Test: Place your hand on your shoulder and feel for any pain or discomfort. If you feel any pain or discomfort, this is an indication that your shoulder may be experiencing shoulder pain.\n",
       "\n",
       "4. Range of Motion Test: Stand with your back against a wall and hold your arms out to the sides. Slowly move your arms out to the sides until you feel a tightness or pain in your shoulder. If you feel pain, this is an indication that your shoulder"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pprint(decoded_finetunned_model.split('<|assistant|>')[-1])\n",
    "display(Markdown(decoded_finetunned_model.split('<|assistant|>')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b4c995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "To screen for understanding shoulder pain, the following steps can be followed:\n",
       "\n",
       "1. Perform a thorough examination of the shoulder joint, including a thorough evaluation of shoulder range of motion, shoulder movement patterns, and shoulder pain.\n",
       "\n",
       "2. Ask the patient to perform a shoulder range of motion exercise, such as bending the arm and rotating the arm, to assess the patient's shoulder mobility.\n",
       "\n",
       "3. Evaluate the patient's shoulder pain by asking about any specific symptoms or areas of pain, such as a lump or a clicking sound in the shoulder joint.\n",
       "\n",
       "4. Assess the patient's ability to perform daily activities, such as brushing their teeth, using a cup, or turning a chair, to determine if the shoulder pain is impacting their daily functioning.\n",
       "\n",
       "5. Ask the patient about any changes in their shoulder function or range of motion over the past few weeks, and consider any changes in their shoulder activities, such as changing jobs or engaging in physical activities that may cause shoulder pain.\n",
       "\n",
       "6. Review the patient's medical history, including any previous shoulder surgeries, injuries, or medications, to determine if any of these factors may be contributing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pprint(decoded_base_model.split('<|assistant|>')[-1])\n",
    "display(Markdown(decoded_base_model.split('<|assistant|>')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e64acdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|assistant|>\\n'\n",
      " 'Proper recovery is an essential aspect of powerlifting. It involves resting '\n",
      " 'and recovering properly after a workout to ensure that the body can recover '\n",
      " 'from the physical demands of lifting weights and prevent injury. Proper '\n",
      " 'recovery helps to prevent muscle damage, reduce soreness, and improve '\n",
      " 'performance. Proper recovery can also help to reduce the risk of injury and '\n",
      " 'improve overall health and fitness. Powerlifters need to ensure that they '\n",
      " 'are properly recovering after a workout to ensure that they can perform at '\n",
      " 'their best in subsequent workouts. Proper recovery techniques include '\n",
      " 'resting, stretching, and taking time off from lifting to allow the body to '\n",
      " 'recover. It is also important to maintain a healthy diet and exercise '\n",
      " 'regularly to ensure that the body is in a state of optimal recovery. Proper '\n",
      " 'recovery is essential for maintaining peak performance and achieving '\n",
      " 'successful powerlifting results.')\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuned_output[finetuned_output.find('<|assistant|>'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53eece4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|assistant|>\\n'\n",
      " 'Proper recovery is an essential aspect of powerlifting. It involves resting '\n",
      " 'and recovering properly after a workout to ensure that the body can recover '\n",
      " 'from the physical demands of lifting weights and prevent injury. Proper '\n",
      " 'recovery helps to prevent muscle damage, reduce soreness, and improve '\n",
      " 'performance. Proper recovery can also help to reduce the risk of injury and '\n",
      " 'improve overall health and fitness. Powerlifters need to ensure that they '\n",
      " 'are properly recovering after a workout to ensure that they can perform at '\n",
      " 'their best in subsequent workouts. Proper recovery techniques include '\n",
      " 'resting, stretching, and taking time off from lifting to allow the body to '\n",
      " 'recover. It is also important to maintain a healthy diet and exercise '\n",
      " 'regularly to ensure that the body is in a state of optimal recovery. Proper '\n",
      " 'recovery is essential for maintaining peak performance and achieving '\n",
      " 'successful powerlifting results.')\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuned_output[base_output.find('<|assistant|>'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045515d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "new_model_name_ = new_model_name\n",
    "generator = pipeline(\"text-generation\", model=new_model_name_, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fa490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing someone with hip anteversion to lift with a technique requires?\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "H\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"Forcing someone with hip anteversion to lift with a technique requires?\", max_new_tokens=200)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9237ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the importance of proper recovery in powerlifting?\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"What is the importance of proper recovery in powerlifting?\", max_new_tokens=100)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "# Load the dataset from JSON file\n",
    "dataset = load_dataset(\"json\", data_files=\"qa_outputs_100_30072025.json\")[\"train\"]\n",
    "\n",
    "# Merge 'instruction' and 'output' as prompt and target\n",
    "def format_example(example):\n",
    "    prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "dataset = dataset.map(format_example)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"  # Must have access to this model from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,  # Optional: enable quantization to save memory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset_test = dataset_test.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama-output\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WITH VALIDATION #######\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load full dataset (single JSON)\n",
    "dataset = load_dataset(\"json\", data_files=input_json_file_name)[\"train\"]\n",
    "\n",
    "# Split train/val\n",
    "splits = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = splits[\"train\"]\n",
    "val_dataset = splits[\"test\"]\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Create Trainer with validation set\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
