{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d4d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d8e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#new \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6fccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from JSON file\n",
    "input_json_file_name = \"cleaned_343_qa_outputs_800_batch16_4bit_30072025.json\"\n",
    "dataset = load_dataset(\"json\", data_files=input_json_file_name)[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f472e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'instruction' and 'output' as prompt and target\n",
    "def format_example(example):\n",
    "    prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3405eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(format_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439cf417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"Consult your healthcare provider before starting any exercise program. Follow all instructions carefully and consult your doctor before starting any new medication or supplement. Keep your workout routine challenging but safe, and avoid overdoing it. Remember to listen to your body and rest when you feel too tired or sore. If you're unsure about a medical condition or treatment plan, consult your doctor first?.\", 'output': 'A healthy, active lifestyle can improve your overall wellness and reduce the risk of chronic diseases like diabetes and heart disease. Follow these tips and stay on top of your exercise and nutrition routines to achieve your goals.', 'text': \"### Instruction:\\nConsult your healthcare provider before starting any exercise program. Follow all instructions carefully and consult your doctor before starting any new medication or supplement. Keep your workout routine challenging but safe, and avoid overdoing it. Remember to listen to your body and rest when you feel too tired or sore. If you're unsure about a medical condition or treatment plan, consult your doctor first?.\\n\\n### Response:\\nA healthy, active lifestyle can improve your overall wellness and reduce the risk of chronic diseases like diabetes and heart disease. Follow these tips and stay on top of your exercise and nutrition routines to achieve your goals.\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c18203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",  # You can also use \"fp4\"\n",
    "#     bnb_4bit_compute_dtype=\"float16\"\n",
    "# )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=quant_config,\n",
    "#     trust_remote_code=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     load_in_4bit=True,  # Optional: enable quantization to save memory\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# # Apply LoRA\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=16,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # Tokenize the dataset\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Training setup\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./lora-llama-output\",\n",
    "#     per_device_train_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     learning_rate=2e-4,\n",
    "#     num_train_epochs=3,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     fp16=True,\n",
    "#     save_total_limit=2,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=500,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator\n",
    "# )\n",
    "\n",
    "# # Start training\n",
    "# trainer.train()\n",
    "#TrainOutput(global_step=129, training_loss=1.575617376224015, metrics={'train_runtime': 199.0944, 'train_samples_per_second': 5.168, 'train_steps_per_second': 0.648, 'total_flos': 3273745332436992.0, 'train_loss': 1.575617376224015, 'epoch': 3.0})\n",
    "## new_model_name = \"tinyllama-qa-343samples-finetuned-30072025\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0247b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_419553/4073768006.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [860/860 21:55, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.906100</td>\n",
       "      <td>1.956670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.908100</td>\n",
       "      <td>1.838620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.737400</td>\n",
       "      <td>1.735574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.606700</td>\n",
       "      <td>1.687118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.622300</td>\n",
       "      <td>1.645923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.599600</td>\n",
       "      <td>1.621207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.585900</td>\n",
       "      <td>1.607686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.379700</td>\n",
       "      <td>1.601775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=860, training_loss=1.7047795207001442, metrics={'train_runtime': 1317.3933, 'train_samples_per_second': 5.207, 'train_steps_per_second': 0.653, 'total_flos': 2.181310005116928e+16, 'train_loss': 1.7047795207001442, 'epoch': 20.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Updated after 1st atempt\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # You can also use \"fp4\"\n",
    "    bnb_4bit_compute_dtype=\"float16\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    #r=8, With small data, a smaller r (e.g., 4) might prevent overfitting\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "    lora_dropout=0.05, #You could try slightly higher (0.1) if overfitting.\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama-output\",\n",
    "    #per_device_train_batch_size=2 with gradient_accumulation_steps=4 is fine (effective batch size 8).\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #learning_rate=2e-4, 2e-4 is a bit high for fine-tuning on a small dataset. It can cause unstable training or forgetting.\n",
    "    learning_rate=1e-5,\n",
    "    #num_train_epochs=3, #With only ~300 samples, 3 epochs might be too little.\n",
    "    num_train_epochs=20,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\", \n",
    "    #Add weight decay, Helps regularize, reduce overfitting.\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    # Used train data also as eval\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "#old  TrainOutput(global_step=129, training_loss=1.575617376224015, metrics={'train_runtime': 199.0944, 'train_samples_per_second': 5.168, 'train_steps_per_second': 0.648, 'total_flos': 3273745332436992.0, 'train_loss': 1.575617376224015, 'epoch': 3.0})\n",
    "#this TrainOutput(global_step=860, training_loss=1.7047795207001442, metrics={'train_runtime': 1317.3933, 'train_samples_per_second': 5.207, 'train_steps_per_second': 0.653, 'total_flos': 2.181310005116928e+16, 'train_loss': 1.7047795207001442, 'epoch': 20.0})\n",
    "#Step\tTraining Loss\tValidation Loss\n",
    "# 100\t1.906100\t1.956670\n",
    "# 200\t1.908100\t1.838620\n",
    "# 300\t1.737400\t1.735574\n",
    "# 400\t1.606700\t1.687118\n",
    "# 500\t1.622300\t1.645923\n",
    "# 600\t1.599600\t1.621207\n",
    "# 700\t1.585900\t1.607686\n",
    "# 800\t1.379700\t1.601775\n",
    "#new_model_name = \"tinyllama-v2-qa-343samples-finetuned-31072025\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9646651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44cff1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tinyllama-v2-qa-343samples-finetuned-31072025/tokenizer_config.json',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-31072025/special_tokens_map.json',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-31072025/chat_template.jinja',\n",
       " 'tinyllama-v2-qa-343samples-finetuned-31072025/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model_name = \"tinyllama-qa-343samples-finetuned-30072025\"\n",
    "new_model_name = \"tinyllama-v2-qa-343samples-finetuned-31072025\"\n",
    "\n",
    "trainer.save_model(new_model_name)\n",
    "tokenizer.save_pretrained(new_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0fca1",
   "metadata": {},
   "source": [
    "# Test NEW model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03445061",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3043de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d2843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Base (Unmodified) Model\n",
    "base_model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load MY Fine-Tuned LoRA Model\n",
    "peft_model_dir = f\"{new_model_name}\"  # Your trained adapter folder\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "\n",
    "# Load base model and apply LoRA weights\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "finetuned_model = PeftModel.from_pretrained(finetuned_model, peft_model_dir)\n",
    "\n",
    "finetuned_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4b0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Base Model Output:\n",
      " <|user|>\n",
      "What is the importance of proper recovery in powerlifting?</s>\n",
      "<|assistant|>\n",
      "Proper recovery is essential for powerlifting athletes to prevent injury, recover from previous workouts, and prepare for future ones. Powerlifting is a high-intensity sport that requires consistent and intense workouts to maintain muscle mass and strength. Without proper recovery, athletes can suffer from muscle damage, fatigue, and soreness, which can limit their performance and prevent them from achieving their goals.\n",
      "\n",
      "Proper recovery involves a series of activities designed to help the body repair and recover from the stresses and strains of intense workouts. These activities include rest, stretching, massage, hydration, and nutrition. Rest helps the body recover from the physical and mental toll of training, while stretching helps to loosen up tight muscles and reduce the risk of injury. Massage and hydration help to reduce inflammation and pain, while nutrition helps to provide the body with the nutrients it needs to repair and recover.\n",
      "\n",
      "Proper recovery is critical for powerlifting athletes because it helps them to perform at their best in future workouts and competitions. By reducing the risk of injury and improving their performance, athletes can achieve their goals\n",
      "\n",
      "ðŸ”¸ Fine-Tuned Model Output:\n",
      " <|user|>\n",
      "What is the importance of proper recovery in powerlifting?</s>\n",
      "<|assistant|>\n",
      "Proper recovery in powerlifting is essential for building and maintaining muscle mass, improving performance, and reducing the risk of injuries. Here are some reasons why proper recovery is important:\n",
      "\n",
      "1. Building muscle mass: Powerlifting is a high-intensity, high-volume exercise that requires significant muscle building. Proper recovery is essential to allow for the repair and growth of muscle tissue, which is critical for building and maintaining muscle mass.\n",
      "\n",
      "2. Improving performance: Powerlifting is a competitive sport, and it requires athletes to perform at their best. Adequate recovery allows for optimal performance, which leads to improved results.\n",
      "\n",
      "3. Reducing the risk of injuries: Proper recovery is essential to prevent muscle strains, tears, and other injuries that can occur during powerlifting. Adequate recovery helps to reduce the risk of injury and improve overall safety.\n",
      "\n",
      "4. Enhancing performance: Adequate recovery helps to improve the overall quality of performance during powerlifting. A well-rested athlete is better able to recover from workouts and perform at their best.\n",
      "\n",
      "5. Maint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"What is the importance of proper recovery in powerlifting?\"\n",
    "prompt = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "formatted_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Base model generation\n",
    "base_pipe = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer)\n",
    "base_output = base_pipe(formatted_prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)[0][\"generated_text\"]\n",
    "\n",
    "# Fine-tuned model generation\n",
    "finetuned_pipe = pipeline(\"text-generation\", model=finetuned_model, tokenizer=tokenizer)\n",
    "finetuned_output = finetuned_pipe(formatted_prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)[0][\"generated_text\"]\n",
    "\n",
    "# Compare\n",
    "print(\"ðŸ”¹ Base Model Output:\\n\", base_output)\n",
    "print(\"\\nðŸ”¸ Fine-Tuned Model Output:\\n\", finetuned_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1aea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "how to screen for understanding shoulder pain? \n",
      "<|assistant|>\n",
      "To screen for understanding shoulder pain, the following steps can be followed:\n",
      "\n",
      "1. Identify the symptoms: The first step is to identify the symptoms of shoulder pain. Some common symptoms include:\n",
      "\n",
      "   - Discomfort or pain in the shoulder joint\n",
      "   - Slow or painful movements\n",
      "   - Impaired motion\n",
      "   - Difficulty with arm rotation\n",
      "   - Trouble lifting or carrying objects\n",
      "\n",
      "2. Assess range of motion: Assessing the range of motion (ROM) of the shoulder joint can help identify any limitations or restrictions. A physician or physical therapist can perform the following tests:\n",
      "\n",
      "   - Shoulder abduction, external rotation, and internal rotation tests\n",
      "   - Biceps brachii testing (pressure on the biceps tendon)\n",
      "   - Dips and lateral raises\n",
      "\n",
      "3. Evaluate strength: Strength assessment can help identify if there are any weaknesses or imbalances in the shoulder muscles. A physician or physical therapist can perform the following tests:\n",
      "\n",
      "   - Curl test\n",
      "   - Shoulder-press test\n",
      "   - Shoulder-chin-\n"
     ]
    }
   ],
   "source": [
    "message = \"how to screen for understanding shoulder pain?\"\n",
    "#\"What is the 'no pain, no gain' mantra?\"\n",
    "#\"What is the importance of proper recovery in powerlifting?\"\n",
    "prompt = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "formatted_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "\n",
    "outputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")  # or \"cpu\"\n",
    "response_base_model = base_model.generate(\n",
    "    **outputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,         # enables sampling for variability\n",
    "    top_p=0.9,               # nucleus sampling\n",
    "    temperature=0.7,         # randomness control\n",
    "    pad_token_id=tokenizer.eos_token_id  # avoid pad token issues\n",
    ")\n",
    "decoded_base_model = tokenizer.decode(response_base_model[0], skip_special_tokens=True)\n",
    "print(decoded_base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d1558d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "how to screen for understanding shoulder pain? \n",
      "<|assistant|>\n",
      "To screen for understanding shoulder pain, you can use the following techniques:\n",
      "\n",
      "1. Shoulder pain history: Ask the patient to describe their shoulder pain history, including any previous shoulder injuries or surgeries, and any pain or discomfort they have experienced.\n",
      "\n",
      "2. Shoulder range of motion (ROM): Ask the patient to perform shoulder ROM exercises, such as arm circles or shoulder rotations, to evaluate their shoulder ROM and determine if they have any shoulder impingement or instability.\n",
      "\n",
      "3. Shoulder function: Ask the patient to perform shoulder exercises, such as shoulder presses or overhead shoulder pulls, to evaluate their shoulder function and determine if they have any weakness or impingement.\n",
      "\n",
      "4. Clinical examination: Use a clinical examination to assess the patient's shoulder pain, including their range of motion, shoulder ROM, shoulder function, and any other symptoms or findings.\n",
      "\n",
      "5. Diagnostic imaging: If the patient has previously undergone shoulder surgery or has shoulder pain that is not associated with a specific injury, consider using diagnostic imaging such as X-rays, MRI, or CT scans to\n"
     ]
    }
   ],
   "source": [
    "outputs_finetunned = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")  # or \"cpu\"\n",
    "\n",
    "response_finetunned_model = finetuned_model.generate(\n",
    "    **outputs_finetunned,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,         # enables sampling for variability\n",
    "    top_p=0.9,               # nucleus sampling\n",
    "    temperature=0.7,         # randomness control\n",
    "    pad_token_id=tokenizer.eos_token_id  # avoid pad token issues\n",
    ")\n",
    "decoded_finetunned_model = tokenizer.decode(response_finetunned_model[0], skip_special_tokens=True)\n",
    "print(decoded_finetunned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "To screen for understanding shoulder pain, you can use the following techniques:\n",
       "\n",
       "1. Shoulder pain history: Ask the patient to describe their shoulder pain history, including any previous shoulder injuries or surgeries, and any pain or discomfort they have experienced.\n",
       "\n",
       "2. Shoulder range of motion (ROM): Ask the patient to perform shoulder ROM exercises, such as arm circles or shoulder rotations, to evaluate their shoulder ROM and determine if they have any shoulder impingement or instability.\n",
       "\n",
       "3. Shoulder function: Ask the patient to perform shoulder exercises, such as shoulder presses or overhead shoulder pulls, to evaluate their shoulder function and determine if they have any weakness or impingement.\n",
       "\n",
       "4. Clinical examination: Use a clinical examination to assess the patient's shoulder pain, including their range of motion, shoulder ROM, shoulder function, and any other symptoms or findings.\n",
       "\n",
       "5. Diagnostic imaging: If the patient has previously undergone shoulder surgery or has shoulder pain that is not associated with a specific injury, consider using diagnostic imaging such as X-rays, MRI, or CT scans to"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pprint(decoded_finetunned_model.split('<|assistant|>')[-1])\n",
    "display(Markdown(decoded_finetunned_model.split('<|assistant|>')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "To screen for understanding shoulder pain, the following steps can be followed:\n",
       "\n",
       "1. Identify the symptoms: The first step is to identify the symptoms of shoulder pain. Some common symptoms include:\n",
       "\n",
       "   - Discomfort or pain in the shoulder joint\n",
       "   - Slow or painful movements\n",
       "   - Impaired motion\n",
       "   - Difficulty with arm rotation\n",
       "   - Trouble lifting or carrying objects\n",
       "\n",
       "2. Assess range of motion: Assessing the range of motion (ROM) of the shoulder joint can help identify any limitations or restrictions. A physician or physical therapist can perform the following tests:\n",
       "\n",
       "   - Shoulder abduction, external rotation, and internal rotation tests\n",
       "   - Biceps brachii testing (pressure on the biceps tendon)\n",
       "   - Dips and lateral raises\n",
       "\n",
       "3. Evaluate strength: Strength assessment can help identify if there are any weaknesses or imbalances in the shoulder muscles. A physician or physical therapist can perform the following tests:\n",
       "\n",
       "   - Curl test\n",
       "   - Shoulder-press test\n",
       "   - Shoulder-chin-"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pprint(decoded_base_model.split('<|assistant|>')[-1])\n",
    "display(Markdown(decoded_base_model.split('<|assistant|>')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e64acdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|assistant|>\\n'\n",
      " 'Proper recovery is an essential aspect of powerlifting. It involves resting '\n",
      " 'and recovering properly after a workout to ensure that the body can recover '\n",
      " 'from the physical demands of lifting weights and prevent injury. Proper '\n",
      " 'recovery helps to prevent muscle damage, reduce soreness, and improve '\n",
      " 'performance. Proper recovery can also help to reduce the risk of injury and '\n",
      " 'improve overall health and fitness. Powerlifters need to ensure that they '\n",
      " 'are properly recovering after a workout to ensure that they can perform at '\n",
      " 'their best in subsequent workouts. Proper recovery techniques include '\n",
      " 'resting, stretching, and taking time off from lifting to allow the body to '\n",
      " 'recover. It is also important to maintain a healthy diet and exercise '\n",
      " 'regularly to ensure that the body is in a state of optimal recovery. Proper '\n",
      " 'recovery is essential for maintaining peak performance and achieving '\n",
      " 'successful powerlifting results.')\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuned_output[finetuned_output.find('<|assistant|>'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53eece4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<|assistant|>\\n'\n",
      " 'Proper recovery is an essential aspect of powerlifting. It involves resting '\n",
      " 'and recovering properly after a workout to ensure that the body can recover '\n",
      " 'from the physical demands of lifting weights and prevent injury. Proper '\n",
      " 'recovery helps to prevent muscle damage, reduce soreness, and improve '\n",
      " 'performance. Proper recovery can also help to reduce the risk of injury and '\n",
      " 'improve overall health and fitness. Powerlifters need to ensure that they '\n",
      " 'are properly recovering after a workout to ensure that they can perform at '\n",
      " 'their best in subsequent workouts. Proper recovery techniques include '\n",
      " 'resting, stretching, and taking time off from lifting to allow the body to '\n",
      " 'recover. It is also important to maintain a healthy diet and exercise '\n",
      " 'regularly to ensure that the body is in a state of optimal recovery. Proper '\n",
      " 'recovery is essential for maintaining peak performance and achieving '\n",
      " 'successful powerlifting results.')\n"
     ]
    }
   ],
   "source": [
    "pprint(finetuned_output[base_output.find('<|assistant|>'):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045515d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "new_model_name_ = new_model_name\n",
    "generator = pipeline(\"text-generation\", model=new_model_name_, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fa490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing someone with hip anteversion to lift with a technique requires?\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "Hip Anteposition? I need some advice on a hip anteposition exercise.\n",
      "Hip Anteversion? I need some advice on a hip anteversion exercise.\n",
      "H\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"Forcing someone with hip anteversion to lift with a technique requires?\", max_new_tokens=200)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9237ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the importance of proper recovery in powerlifting?\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"What is the importance of proper recovery in powerlifting?\", max_new_tokens=100)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "# Load the dataset from JSON file\n",
    "dataset = load_dataset(\"json\", data_files=\"qa_outputs_100_30072025.json\")[\"train\"]\n",
    "\n",
    "# Merge 'instruction' and 'output' as prompt and target\n",
    "def format_example(example):\n",
    "    prompt = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return {\"text\": prompt}\n",
    "\n",
    "dataset = dataset.map(format_example)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"  # Must have access to this model from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,  # Optional: enable quantization to save memory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # These depend on the model\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama-output\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### WITH VALIDATION #######\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load full dataset (single JSON)\n",
    "dataset = load_dataset(\"json\", data_files=input_json_file_name)[\"train\"]\n",
    "\n",
    "# Split train/val\n",
    "splits = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = splits[\"train\"]\n",
    "val_dataset = splits[\"test\"]\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Create Trainer with validation set\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
